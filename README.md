# cloud-phase-prediction

## Getting start
1. Run the model training: 
`python model.py --training_data_path='/umbc/rs/nasa-access/data/calipso-viirs-merged/aerosol_free/'  --model_saving_path='/umbc/rs/nasa-access/xin/cloud-phase-prediction/model/' `
2. Note you can supply the training data into directory --training_data_path you define and the trained model will be save at the specified directory --model_saving_path.  

## Dataset
The model takes two satalitte datasets Calipso and Viirs as input. The attributes of each dataset are specifed in Table 1, 2, 3 in ["Deep Multi-Sensor Domain Adaptation on Active and Passive Satellite Remote Sensing Data"](http://mason.gmu.edu/~lzhao9/venues/DeepSpatial2020/papers/DeepSpatial2020_paper_14_camera_ready.pdf). 

## DAMA Model
The remote satellite sensing data raises more challenges as the data captured by passive sensor and active Lidar are high dimensional, globally covered and heterogeneous in nature. In this paper, we propose an end-to-end deep domain adaptation with domain mapping and correlation alignment (DAMA) and apply it to classify the heterogeneous remote satellite cloud and aerosol types. In training phase, there are two branches of inputs that are source domain data features and target domain data features that have different dimensionalities and heterogeneous feature spaces. Our model introduces a heterogeneous domain mapping to transform the feature space of target domain into the feature space of source domain, and uses feature extraction layer to train the shared representative features between the source and target domain. At last, it adds a correlation layer to the end of the shared layers, inspired by the idea of correlation alignment introduced in. By incorporating the correlation loss and classification loss in training the domain adaptation network, we find the network can maximize the classification accuracy on the target domain by minimizing the difference in the second-order statistics between the source and target domains. In the testing phase, only VIIRS (target domain) data is fed into the deep neural network by going through the deep domain mapping layer and feature extraction layer. The trained source classifier can then be applied to classify the output of the feature extraction layer as the domain invariant feature representation has been generated from the flow. 